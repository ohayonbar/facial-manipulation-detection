# facial-manipulation-detection
Implementation of deep learning models for detecting facial manipulation, including deepfakes (face swaps) and GAN-generated synthetic faces. Features SimpleNet and Xception-based architectures with visualization tools for model interpretation.

## Overview

This project implements Computer Vision techniques to distinguish between real face images and manipulated face images. Two types of manipulations are considered:
- **Deepfakes**: Images generated by taking a face of one subject and planting it in another subject's context
- **Synthetic images**: Images fully generated by GANs (Progressive GAN) trained against the CelebA-HQ dataset

## Project Structure

```
├── common.py                  # Constants and repository locations
├── utils.py                   # Utility functions to load models and datasets
├── faces_dataset.py           # Dataset module for face images
├── show_faces_dataset.py      # Script to plot dataset samples
├── train_main.py              # Main training script
├── trainer.py                 # Abstract training class
├── plot_accuracy_and_loss.py  # Script to visualize metrics
├── numerical_analysis.py      # Script for ROC and DET curves
├── saliency_map.py            # Gradients visualization tool
├── grad_cam_analysis.py       # Class activation map visualization
├── models.py                  # Model architectures
├── xception.py                # Xception model implementation
└── run_me.sh                  # Shell script to run all components
```

## Dataset

The dataset used in this project is too large to be included in the repository. To run this code, you'll need to:

1. Download the dataset from the Tel-Aviv University course Moodle (for TAU students)
2. Extract the files to a directory named `datasets` in the root of this project
3. Ensure the directory structure looks like:
   ```
   datasets/
   ├── fakes_dataset/
   │   ├── real/
   │   └── fake/
   └── synthetic_dataset/
       ├── real/
       └── synthetic/
   ```

For those outside TAU looking to replicate this project, similar datasets include:
- [FaceForensics++](https://github.com/ondyari/FaceForensics) for deepfake detection
- [CelebA-HQ](https://github.com/tkarras/progressive_growing_of_gans) for synthetic faces

## Models

### SimpleNet
A vanilla deep neural network that serves as a baseline for performance comparison.

### XceptionBased
A fine-tuned Xception model with a custom MLP head consisting of:
- Fully-Connected 2048x1000 → ReLU
- Fully-Connected 1000x256 → ReLU
- Fully-Connected 256x64 → ReLU
- Fully-Connected 64x2

## Setup and Installation

```bash
# Clone this repository
git clone https://github.com/yourusername/facial-manipulation-detection.git
cd facial-manipulation-detection

# Create conda environment from yml file
conda env create -f environment.yml
conda activate cv-face-detection

# Or install dependencies manually
pip install pillow numpy scipy matplotlib opencv-python torch torchvision pytorch-grad-cam
```

## Usage

### Training Models

```bash
# Train SimpleNet on Deepfakes dataset
python train_main.py -d fakes_dataset -m SimpleNet --lr 0.001 -b 32 -e 5 -o Adam

# Train SimpleNet on Synthetic dataset
python train_main.py -d synthetic_dataset -m SimpleNet --lr 0.001 -b 32 -e 5 -o Adam

# Train XceptionBased on Synthetic dataset
python train_main.py -d synthetic_dataset -m XceptionBased --lr 0.001 -b 32 -e 2 -o Adam
```

### Analysis and Visualization

```bash
# Plot accuracy and loss
python plot_accuracy_and_loss.py -m SimpleNet -j out/fakes_dataset_SimpleNet_Adam.json -d fakes_dataset

# Generate ROC and DET curves
python numerical_analysis.py -m SimpleNet -cpp checkpoints/fakes_dataset_SimpleNet_Adam.pt -d fakes_dataset

# Generate saliency maps
python saliency_map.py -m SimpleNet -cpp checkpoints/fakes_dataset_SimpleNet_Adam.pt -d fakes_dataset

# Generate Grad-CAM visualizations
python grad_cam_analysis.py -m XceptionBased -cpp checkpoints/synthetic_dataset_XceptionBased_Adam.pt -d synthetic_dataset
```

### Running Everything

To run all training and analysis scripts, use:
```bash
./run_me.sh
```

## Results

The project demonstrates how models can be trained to detect manipulated faces and includes several analysis tools to understand what features the models are learning:

### Performance Metrics
- Training and validation accuracy/loss curves
- ROC and DET curves for model evaluation
- AuC (Area under Curve) scores

### Visualization Tools
- Saliency maps showing the contribution of each pixel to the classification
- Grad-CAM highlighting regions of interest in the images that influence the model's decision
